{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":105,"outputs":[{"output_type":"stream","text":"/kaggle/input/widsdatathon2021/SampleSubmissionWiDS2021.csv\n/kaggle/input/widsdatathon2021/SolutionTemplateWiDS2021.csv\n/kaggle/input/widsdatathon2021/DataDictionaryWiDS2021.csv\n/kaggle/input/widsdatathon2021/UnlabeledWiDS2021.csv\n/kaggle/input/widsdatathon2021/TrainingWiDS2021.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# **Load Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_COL = 'diabetes_mellitus'\n\n#Load Data\ndf_train = pd.read_csv('/kaggle/input/widsdatathon2021/TrainingWiDS2021.csv',index_col=0)\ndf_test = pd.read_csv('/kaggle/input/widsdatathon2021/UnlabeledWiDS2021.csv',index_col=0)\ndf_dict = pd.read_csv('/kaggle/input/widsdatathon2021/DataDictionaryWiDS2021.csv')\ndf_sample = pd.read_csv('/kaggle/input/widsdatathon2021/SampleSubmissionWiDS2021.csv')\ndf_template = pd.read_csv('/kaggle/input/widsdatathon2021/SolutionTemplateWiDS2021.csv')\n\n#Display\ndisplay(df_train.head())","execution_count":106,"outputs":[{"output_type":"display_data","data":{"text/plain":"   encounter_id  hospital_id   age        bmi  elective_surgery  ethnicity  \\\n1        214826          118  68.0  22.732803                 0  Caucasian   \n2        246060           81  77.0  27.421875                 0  Caucasian   \n3        276985          118  25.0  31.952749                 0  Caucasian   \n4        262220          118  81.0  22.635548                 1  Caucasian   \n5        201746           33  19.0        NaN                 0  Caucasian   \n\n  gender  height hospital_admit_source           icu_admit_source  ...  \\\n1      M   180.3                 Floor                      Floor  ...   \n2      F   160.0                 Floor                      Floor  ...   \n3      F   172.7  Emergency Department       Accident & Emergency  ...   \n4      F   165.1        Operating Room  Operating Room / Recovery  ...   \n5      M   188.0                   NaN       Accident & Emergency  ...   \n\n   h1_pao2fio2ratio_max h1_pao2fio2ratio_min aids  cirrhosis  hepatic_failure  \\\n1                   NaN                  NaN    0          0                0   \n2                  51.0                 51.0    0          0                0   \n3                   NaN                  NaN    0          0                0   \n4                 337.0                337.0    0          0                0   \n5                   NaN                  NaN    0          0                0   \n\n   immunosuppression  leukemia  lymphoma  solid_tumor_with_metastasis  \\\n1                  0         0         0                            0   \n2                  0         0         0                            0   \n3                  0         0         0                            0   \n4                  0         0         0                            0   \n5                  0         0         0                            0   \n\n   diabetes_mellitus  \n1                  1  \n2                  1  \n3                  0  \n4                  0  \n5                  0  \n\n[5 rows x 180 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encounter_id</th>\n      <th>hospital_id</th>\n      <th>age</th>\n      <th>bmi</th>\n      <th>elective_surgery</th>\n      <th>ethnicity</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>hospital_admit_source</th>\n      <th>icu_admit_source</th>\n      <th>...</th>\n      <th>h1_pao2fio2ratio_max</th>\n      <th>h1_pao2fio2ratio_min</th>\n      <th>aids</th>\n      <th>cirrhosis</th>\n      <th>hepatic_failure</th>\n      <th>immunosuppression</th>\n      <th>leukemia</th>\n      <th>lymphoma</th>\n      <th>solid_tumor_with_metastasis</th>\n      <th>diabetes_mellitus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>214826</td>\n      <td>118</td>\n      <td>68.0</td>\n      <td>22.732803</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>M</td>\n      <td>180.3</td>\n      <td>Floor</td>\n      <td>Floor</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>246060</td>\n      <td>81</td>\n      <td>77.0</td>\n      <td>27.421875</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>F</td>\n      <td>160.0</td>\n      <td>Floor</td>\n      <td>Floor</td>\n      <td>...</td>\n      <td>51.0</td>\n      <td>51.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>276985</td>\n      <td>118</td>\n      <td>25.0</td>\n      <td>31.952749</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>F</td>\n      <td>172.7</td>\n      <td>Emergency Department</td>\n      <td>Accident &amp; Emergency</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>262220</td>\n      <td>118</td>\n      <td>81.0</td>\n      <td>22.635548</td>\n      <td>1</td>\n      <td>Caucasian</td>\n      <td>F</td>\n      <td>165.1</td>\n      <td>Operating Room</td>\n      <td>Operating Room / Recovery</td>\n      <td>...</td>\n      <td>337.0</td>\n      <td>337.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>201746</td>\n      <td>33</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>M</td>\n      <td>188.0</td>\n      <td>NaN</td>\n      <td>Accident &amp; Emergency</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 180 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","execution_count":107,"outputs":[{"output_type":"stream","text":"(130157, 180)\n(10234, 179)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.nunique())\nprint(df_train.dtypes)","execution_count":108,"outputs":[{"output_type":"stream","text":"encounter_id                   130157\nhospital_id                       204\nage                                75\nbmi                             41453\nelective_surgery                    2\n                                ...  \nimmunosuppression                   2\nleukemia                            2\nlymphoma                            2\nsolid_tumor_with_metastasis         2\ndiabetes_mellitus                   2\nLength: 180, dtype: int64\nencounter_id                     int64\nhospital_id                      int64\nage                            float64\nbmi                            float64\nelective_surgery                 int64\n                                ...   \nimmunosuppression                int64\nleukemia                         int64\nlymphoma                         int64\nsolid_tumor_with_metastasis      int64\ndiabetes_mellitus                int64\nLength: 180, dtype: object\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target Variable Distribution in Training\ndf_train.groupby('diabetes_mellitus').encounter_id.count()","execution_count":109,"outputs":[{"output_type":"execute_result","execution_count":109,"data":{"text/plain":"diabetes_mellitus\n0    102006\n1     28151\nName: encounter_id, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the id columns\nid_cols = ['encounter_id','hospital_id','icu_id']\ntest_id = df_test['encounter_id']\ndf_train.drop(id_cols, axis=1, inplace=True)\ndf_test.drop(id_cols, axis=1, inplace=True)","execution_count":110,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop columns that have over 80% missing value\ndrop_cols = ['h1_diasbp_invasive_max', 'h1_diasbp_invasive_min',\n       'h1_mbp_invasive_max', 'h1_mbp_invasive_min',\n       'h1_sysbp_invasive_max', 'h1_sysbp_invasive_min', 'h1_albumin_max',\n       'h1_albumin_min', 'h1_bilirubin_max', 'h1_bilirubin_min',\n       'h1_bun_max', 'h1_bun_min', 'h1_calcium_max', 'h1_calcium_min',\n       'h1_creatinine_max', 'h1_creatinine_min', 'h1_hco3_max',\n       'h1_hco3_min', 'h1_lactate_max', 'h1_lactate_min',\n       'h1_platelets_max', 'h1_platelets_min', 'h1_wbc_max', 'h1_wbc_min',\n       'h1_arterial_pco2_max', 'h1_arterial_pco2_min',\n       'h1_arterial_ph_max', 'h1_arterial_ph_min', 'h1_arterial_po2_max',\n       'h1_arterial_po2_min', 'h1_pao2fio2ratio_max',\n       'h1_pao2fio2ratio_min']\ndf_train.drop(drop_cols, axis=1, inplace=True)\ndf_test.drop(drop_cols, axis=1, inplace=True)","execution_count":111,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train['readmission_status'].unique())\nprint(df_test['readmission_status'].unique())\n\n# Drop readmission_status column\ndf_train.drop(\"readmission_status\", axis=1, inplace=True)\ndf_test.drop(\"readmission_status\", axis=1, inplace=True)","execution_count":112,"outputs":[{"output_type":"stream","text":"[0]\n[0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Correlated Columns\ncor_cols = ['paco2_for_ph_apache', 'h1_inr_max', 'h1_inr_min']\ndf_train.drop(cor_cols, axis=1, inplace=True)\ndf_test.drop(cor_cols, axis=1, inplace=True)","execution_count":113,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe().T","execution_count":114,"outputs":[{"output_type":"execute_result","execution_count":114,"data":{"text/plain":"                                count        mean        std         min  \\\nage                          125169.0   61.995103  16.822880    0.000000   \nbmi                          125667.0   29.110260   8.262776   14.844926   \nelective_surgery             130157.0    0.189840   0.392176    0.000000   \nheight                       128080.0  169.607219  10.833085  137.200000   \npre_icu_los_days             130157.0    0.839933   2.485337   -0.250000   \n...                               ...         ...        ...         ...   \nimmunosuppression            130157.0    0.025669   0.158146    0.000000   \nleukemia                     130157.0    0.007307   0.085166    0.000000   \nlymphoma                     130157.0    0.004187   0.064574    0.000000   \nsolid_tumor_with_metastasis  130157.0    0.020852   0.142888    0.000000   \ndiabetes_mellitus            130157.0    0.216285   0.411712    0.000000   \n\n                                    25%         50%         75%         max  \nage                           52.000000   64.000000   75.000000   89.000000  \nbmi                           23.598006   27.564749   32.803127   67.814990  \nelective_surgery               0.000000    0.000000    0.000000    1.000000  \nheight                       162.500000  170.100000  177.800000  195.590000  \npre_icu_los_days               0.045833    0.155556    0.423611  175.627778  \n...                                 ...         ...         ...         ...  \nimmunosuppression              0.000000    0.000000    0.000000    1.000000  \nleukemia                       0.000000    0.000000    0.000000    1.000000  \nlymphoma                       0.000000    0.000000    0.000000    1.000000  \nsolid_tumor_with_metastasis    0.000000    0.000000    0.000000    1.000000  \ndiabetes_mellitus              0.000000    0.000000    0.000000    1.000000  \n\n[135 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>125169.0</td>\n      <td>61.995103</td>\n      <td>16.822880</td>\n      <td>0.000000</td>\n      <td>52.000000</td>\n      <td>64.000000</td>\n      <td>75.000000</td>\n      <td>89.000000</td>\n    </tr>\n    <tr>\n      <th>bmi</th>\n      <td>125667.0</td>\n      <td>29.110260</td>\n      <td>8.262776</td>\n      <td>14.844926</td>\n      <td>23.598006</td>\n      <td>27.564749</td>\n      <td>32.803127</td>\n      <td>67.814990</td>\n    </tr>\n    <tr>\n      <th>elective_surgery</th>\n      <td>130157.0</td>\n      <td>0.189840</td>\n      <td>0.392176</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>height</th>\n      <td>128080.0</td>\n      <td>169.607219</td>\n      <td>10.833085</td>\n      <td>137.200000</td>\n      <td>162.500000</td>\n      <td>170.100000</td>\n      <td>177.800000</td>\n      <td>195.590000</td>\n    </tr>\n    <tr>\n      <th>pre_icu_los_days</th>\n      <td>130157.0</td>\n      <td>0.839933</td>\n      <td>2.485337</td>\n      <td>-0.250000</td>\n      <td>0.045833</td>\n      <td>0.155556</td>\n      <td>0.423611</td>\n      <td>175.627778</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>immunosuppression</th>\n      <td>130157.0</td>\n      <td>0.025669</td>\n      <td>0.158146</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>leukemia</th>\n      <td>130157.0</td>\n      <td>0.007307</td>\n      <td>0.085166</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>lymphoma</th>\n      <td>130157.0</td>\n      <td>0.004187</td>\n      <td>0.064574</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>solid_tumor_with_metastasis</th>\n      <td>130157.0</td>\n      <td>0.020852</td>\n      <td>0.142888</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>diabetes_mellitus</th>\n      <td>130157.0</td>\n      <td>0.216285</td>\n      <td>0.411712</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>135 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_count = df_train.isna().sum()\nmissing_df = (pd.concat([missing_count.rename('Missing count'),\n                     missing_count.div(len(df_train))\n                          .rename('Missing ratio')],axis = 1)\n             .loc[missing_count.ne(0)])\nmissing_df","execution_count":115,"outputs":[{"output_type":"execute_result","execution_count":115,"data":{"text/plain":"                      Missing count  Missing ratio\nage                            4988       0.038323\nbmi                            4490       0.034497\nethnicity                      1587       0.012193\ngender                           66       0.000507\nheight                         2077       0.015958\n...                             ...            ...\nd1_arterial_ph_min            84807       0.651575\nd1_arterial_po2_max           84010       0.645451\nd1_arterial_po2_min           84010       0.645451\nd1_pao2fio2ratio_max          93339       0.717126\nd1_pao2fio2ratio_min          93339       0.717126\n\n[125 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing count</th>\n      <th>Missing ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>4988</td>\n      <td>0.038323</td>\n    </tr>\n    <tr>\n      <th>bmi</th>\n      <td>4490</td>\n      <td>0.034497</td>\n    </tr>\n    <tr>\n      <th>ethnicity</th>\n      <td>1587</td>\n      <td>0.012193</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>66</td>\n      <td>0.000507</td>\n    </tr>\n    <tr>\n      <th>height</th>\n      <td>2077</td>\n      <td>0.015958</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>d1_arterial_ph_min</th>\n      <td>84807</td>\n      <td>0.651575</td>\n    </tr>\n    <tr>\n      <th>d1_arterial_po2_max</th>\n      <td>84010</td>\n      <td>0.645451</td>\n    </tr>\n    <tr>\n      <th>d1_arterial_po2_min</th>\n      <td>84010</td>\n      <td>0.645451</td>\n    </tr>\n    <tr>\n      <th>d1_pao2fio2ratio_max</th>\n      <td>93339</td>\n      <td>0.717126</td>\n    </tr>\n    <tr>\n      <th>d1_pao2fio2ratio_min</th>\n      <td>93339</td>\n      <td>0.717126</td>\n    </tr>\n  </tbody>\n</table>\n<p>125 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nplt.figure(figsize = (16,8))\nplt.title('Hospital Admit Source', size = 20)\nsns.countplot(y ='hospital_admit_source', data = df_train); \n\"\"\"","execution_count":116,"outputs":[{"output_type":"execute_result","execution_count":116,"data":{"text/plain":"\"\\nplt.figure(figsize = (16,8))\\nplt.title('Hospital Admit Source', size = 20)\\nsns.countplot(y ='hospital_admit_source', data = df_train); \\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nplt.figure(figsize = (16,8))\nplt.title('ICU Admit Source', size = 20)\nsns.countplot(y ='icu_admit_source', data = df_train)\n\"\"\"","execution_count":117,"outputs":[{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"\"\\nplt.figure(figsize = (16,8))\\nplt.title('ICU Admit Source', size = 20)\\nsns.countplot(y ='icu_admit_source', data = df_train)\\n\""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Encoding & Imputation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Print the categorical columns\nprint([col for col in df_train.columns if (1<df_train[col].nunique()) & (df_train[col].dtype != np.number)& (df_train[col].dtype != int) ])","execution_count":118,"outputs":[{"output_type":"stream","text":"['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols =  ['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type']\n\n## Handle na values\ndf_train[categorical_cols] = df_train[categorical_cols].fillna(\"NA\")\ndf_test[categorical_cols] = df_test[categorical_cols].fillna(\"NA\")\n\ndf_train[categorical_cols].isna().sum()","execution_count":119,"outputs":[{"output_type":"execute_result","execution_count":119,"data":{"text/plain":"ethnicity                0\ngender                   0\nhospital_admit_source    0\nicu_admit_source         0\nicu_stay_type            0\nicu_type                 0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(df_dict)):\n    if str(df_dict['Data Type'][i])==\"string\":\n        print(df_dict['Variable Name'][i])","execution_count":120,"outputs":[{"output_type":"stream","text":"bmi\nethnicity\ngender\nhospital_admit_source\nicu_admit_source\nicu_admit_type\nicu_stay_type\nicu_type\napache_2_diagnosis\napache_3j_diagnosis\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train['apache_2_diagnosis'].nunique())\nprint(df_train['apache_3j_diagnosis'].nunique())","execution_count":121,"outputs":[{"output_type":"stream","text":"44\n400\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"diagnosis_cols = ['apache_2_diagnosis','apache_3j_diagnosis']","execution_count":122,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(df_dict)):\n    if str(df_dict['Data Type'][i])==\"binary\":\n        print(df_dict['Variable Name'][i])","execution_count":123,"outputs":[{"output_type":"stream","text":"elective_surgery\nreadmission_status\napache_post_operative\narf_apache\ngcs_unable_apache\nintubated_apache\nventilated_apache\naids\ncirrhosis\nhepatic_failure\nimmunosuppression\nleukemia\nlymphoma\nsolid_tumor_with_metastasis\ndiabetes_mellitus\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cols = ['elective_surgery',\n'apache_post_operative',\n'arf_apache',\n'gcs_unable_apache',\n'intubated_apache',\n'ventilated_apache',\n'aids',\n'cirrhosis',\n'hepatic_failure',\n'immunosuppression',\n'leukemia',\n'lymphoma',\n'solid_tumor_with_metastasis']","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#impute weight.\ndf_train.groupby('gender')[\"weight\"].mean()","execution_count":125,"outputs":[{"output_type":"execute_result","execution_count":125,"data":{"text/plain":"gender\nF     77.042256\nM     89.487018\nNA    83.726304\nName: weight, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.groupby('gender')[\"weight\"].mean()","execution_count":126,"outputs":[{"output_type":"execute_result","execution_count":126,"data":{"text/plain":"gender\nF     77.112713\nM     88.836120\nNA    98.640000\nName: weight, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n# impute weight wrt gender\ndf_train[\"weight\"] = np.where(df_train['gender'] == 'F', df_train[\"weight\"].fillna(77.04), df_train[\"weight\"])\ndf_train[\"weight\"] = np.where(df_train['gender'] == 'M', df_train[\"weight\"].fillna(89.49), df_train[\"weight\"])\ndf_train[\"weight\"] = np.where(df_train['gender'] == 'NA', df_train[\"weight\"].fillna(83.73), df_train[\"weight\"])\n\ndf_test[\"weight\"] = np.where(df_test['gender'] == 'F', df_test[\"weight\"].fillna(77.11), df_test[\"weight\"])\ndf_test[\"weight\"] = np.where(df_test['gender'] == 'M', df_test[\"weight\"].fillna(88.84),df_test[\"weight\"])\ndf_test[\"weight\"] = np.where(df_test['gender'] == 'NA', df_test[\"weight\"].fillna(98.64),df_test[\"weight\"])\n\"\"\"","execution_count":127,"outputs":[{"output_type":"execute_result","execution_count":127,"data":{"text/plain":"'\\n# impute weight wrt gender\\ndf_train[\"weight\"] = np.where(df_train[\\'gender\\'] == \\'F\\', df_train[\"weight\"].fillna(77.04), df_train[\"weight\"])\\ndf_train[\"weight\"] = np.where(df_train[\\'gender\\'] == \\'M\\', df_train[\"weight\"].fillna(89.49), df_train[\"weight\"])\\ndf_train[\"weight\"] = np.where(df_train[\\'gender\\'] == \\'NA\\', df_train[\"weight\"].fillna(83.73), df_train[\"weight\"])\\n\\ndf_test[\"weight\"] = np.where(df_test[\\'gender\\'] == \\'F\\', df_test[\"weight\"].fillna(77.11), df_test[\"weight\"])\\ndf_test[\"weight\"] = np.where(df_test[\\'gender\\'] == \\'M\\', df_test[\"weight\"].fillna(88.84),df_test[\"weight\"])\\ndf_test[\"weight\"] = np.where(df_test[\\'gender\\'] == \\'NA\\', df_test[\"weight\"].fillna(98.64),df_test[\"weight\"])\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#impute height.\ndf_train.groupby('gender')[\"height\"].mean()","execution_count":128,"outputs":[{"output_type":"execute_result","execution_count":128,"data":{"text/plain":"gender\nF     161.631668\nM     176.340292\nNA    171.425581\nName: height, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.groupby('gender')[\"height\"].mean()","execution_count":129,"outputs":[{"output_type":"execute_result","execution_count":129,"data":{"text/plain":"gender\nF     161.534660\nM     175.836729\nNA    175.160000\nName: height, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n# impute height wrt gender\ndf_train[\"height\"] = np.where(df_train['gender'] == 'F', df_train[\"height\"].fillna(161.631668), df_train[\"height\"])\ndf_train[\"height\"] = np.where(df_train['gender'] == 'M', df_train[\"height\"].fillna(176.340292), df_train[\"height\"])\ndf_train[\"height\"] = np.where(df_train['gender'] == 'NA', df_train[\"height\"].fillna(171.425581), df_train[\"height\"])\n\ndf_test[\"height\"] = np.where(df_test['gender'] == 'F', df_test[\"height\"].fillna(161.534660), df_test[\"height\"])\ndf_test[\"height\"] = np.where(df_test['gender'] == 'M', df_test[\"height\"].fillna(175.836729),df_test[\"height\"])\ndf_test[\"height\"] = np.where(df_test['gender'] == 'NA', df_test[\"height\"].fillna(175.160000),df_test[\"height\"])\n\"\"\"","execution_count":130,"outputs":[{"output_type":"execute_result","execution_count":130,"data":{"text/plain":"'\\n# impute height wrt gender\\ndf_train[\"height\"] = np.where(df_train[\\'gender\\'] == \\'F\\', df_train[\"height\"].fillna(161.631668), df_train[\"height\"])\\ndf_train[\"height\"] = np.where(df_train[\\'gender\\'] == \\'M\\', df_train[\"height\"].fillna(176.340292), df_train[\"height\"])\\ndf_train[\"height\"] = np.where(df_train[\\'gender\\'] == \\'NA\\', df_train[\"height\"].fillna(171.425581), df_train[\"height\"])\\n\\ndf_test[\"height\"] = np.where(df_test[\\'gender\\'] == \\'F\\', df_test[\"height\"].fillna(161.534660), df_test[\"height\"])\\ndf_test[\"height\"] = np.where(df_test[\\'gender\\'] == \\'M\\', df_test[\"height\"].fillna(175.836729),df_test[\"height\"])\\ndf_test[\"height\"] = np.where(df_test[\\'gender\\'] == \\'NA\\', df_test[\"height\"].fillna(175.160000),df_test[\"height\"])\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can fill the missing values of d1_pao2fio2ratio_max with pao2_apache/fio2_apache\n\ndf_train[\"d1_pao2fio2ratio_max\"] = np.where((df_train[\"pao2_apache\"].notna() \n                                             & df_train[\"fio2_apache\"].notna()\n                                             & df_train[\"d1_pao2fio2ratio_max\"].isna() ), \n                                            df_train[\"pao2_apache\"] / df_train[\"fio2_apache\"], \n                                            df_train[\"d1_pao2fio2ratio_max\"])\ndf_test[\"d1_pao2fio2ratio_max\"] = np.where((df_test[\"pao2_apache\"].notna() \n                                             & df_test[\"fio2_apache\"].notna()\n                                             & df_test[\"d1_pao2fio2ratio_max\"].isna() ), \n                                            df_test[\"pao2_apache\"] / df_test[\"fio2_apache\"], \n                                            df_test[\"d1_pao2fio2ratio_max\"])","execution_count":131,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = df_test[[col for col in df_test if TARGET_COL != col]]\ncat_cols = categorical_cols + binary_cols + diagnosis_cols\nnumerical_cols = [col for col in all_features if col not in cat_cols]","execution_count":132,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n# impute remaining categorical (binary and diagnosis) columns by mode\n\ndef cat_imputation(df):    \n    imputer_cat = SimpleImputer(strategy='most_frequent')\n    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n    return df\n\ndf_train = cat_imputation(df_train)\ndf_test = cat_imputation(df_test)\n","execution_count":133,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# impute remaining numerical columns by mean\nfor n in numerical_cols:\n    df_train[n] = df_train.groupby(['ethnicity','gender'])[n].apply(lambda x: x.fillna(x.mean()))\n    df_test[n] = df_test.groupby(['ethnicity','gender'])[n].apply(lambda x: x.fillna(x.mean()))","execution_count":134,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby('gender')[\"height\"].mean()","execution_count":135,"outputs":[{"output_type":"execute_result","execution_count":135,"data":{"text/plain":"gender\nF     161.632193\nM     176.339539\nNA    171.064848\nName: height, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nfor c in categorical_cols:\n    df_train[c] = OrdinalEncoder(dtype=\"int\").fit_transform(df_train[[c]])\n    df_test[c] = OrdinalEncoder(dtype=\"int\").fit_transform(df_test[[c]])","execution_count":136,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfrom fancyimpute import KNN, NuclearNormMinimization, SoftImpute, IterativeImputer, BiScaler\n\nfill_knn_train = KNN(k=3).fit_transform(df_train)\nfill_knn_test = KNN(k=3).fit_transform(df_test)\ndf_train = pd.DataFrame(fill_knn_train)\ndf_test = pd.DataFrame(fill_knn_test)\n\"\"\"","execution_count":137,"outputs":[{"output_type":"execute_result","execution_count":137,"data":{"text/plain":"'\\nfrom fancyimpute import KNN, NuclearNormMinimization, SoftImpute, IterativeImputer, BiScaler\\n\\nfill_knn_train = KNN(k=3).fit_transform(df_train)\\nfill_knn_test = KNN(k=3).fit_transform(df_test)\\ndf_train = pd.DataFrame(fill_knn_train)\\ndf_test = pd.DataFrame(fill_knn_test)\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n!pip install fancyimpute\nfrom fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\ndef imputation(df):\n    all_features = df[[col for col in df if TARGET_COL != col]]\n    numerical_cols = [col for col in all_features if col not in categorical_cols]\n    df = KNN(k=3).fit_transform(df)\n    return df\n\ndf_train = imputation(df_train)\ndf_test = imputation(df_test)\n\"\"\"","execution_count":138,"outputs":[{"output_type":"execute_result","execution_count":138,"data":{"text/plain":"'\\n!pip install fancyimpute\\nfrom fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\\ndef imputation(df):\\n    all_features = df[[col for col in df if TARGET_COL != col]]\\n    numerical_cols = [col for col in all_features if col not in categorical_cols]\\n    df = KNN(k=3).fit_transform(df)\\n    return df\\n\\ndf_train = imputation(df_train)\\ndf_test = imputation(df_test)\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncompression_opts = dict(method='zip',\n                        archive_name='out.csv')  \ndf_train.to_csv('tarin_out.zip', index=False,\n          compression=compression_opts)  \ndf_test.to_csv('test_out.zip', index=False,\n          compression=compression_opts)  \n","execution_count":139,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deal with Imblanaced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score,roc_curve,auc, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, RUSBoostClassifier","execution_count":140,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(\n     df_train[[c for c in df_train if TARGET_COL != c]], df_train[TARGET_COL], test_size=0.20, random_state=999)\nprint(X_train.shape,X_valid.shape)","execution_count":141,"outputs":[{"output_type":"stream","text":"(104125, 140) (26032, 140)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rdm = RandomOverSampler(random_state=999)\nX_rdm, y_rdm = rdm.fit_resample(X_train, y_train)","execution_count":142,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nmodel = XGBClassifier(tree_method = 'gpu_hist',learning_rate=0.45,n_estimators=164, max_depth=8, min_child_weight=2, random_state=999) \nmodel.fit(X_rdm, y_rdm)\nfeatures = X_train.columns\nprint(f\"AUC is {roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])}\")\nprint(metrics.classification_report(y_valid, model.predict(X_valid), labels=[0, 1]))\n\"\"\"","execution_count":143,"outputs":[{"output_type":"execute_result","execution_count":143,"data":{"text/plain":"'\\nmodel = XGBClassifier(tree_method = \\'gpu_hist\\',learning_rate=0.45,n_estimators=164, max_depth=8, min_child_weight=2, random_state=999) \\nmodel.fit(X_rdm, y_rdm)\\nfeatures = X_train.columns\\nprint(f\"AUC is {roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])}\")\\nprint(metrics.classification_report(y_valid, model.predict(X_valid), labels=[0, 1]))\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(random_state=999, tree_method = 'gpu_hist',boosting_type='gbdt', \n                       num_leaves=64, learning_rate = 0.1,n_estimators = 125, max_depth =10,\n                       min_child_samples=20, min_child_weight=0.002,\n                       reg_alpha=0.0001, reg_lambda=0.0001)\nmodel.fit(X_rdm, y_rdm)\n\nfeatures = X_train.columns\nprint(f\"AUC is {roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])}\")\nprint(metrics.classification_report(y_valid, model.predict(X_valid), labels=[0, 1]))","execution_count":159,"outputs":[{"output_type":"stream","text":"AUC is 0.8516107191246647\n              precision    recall  f1-score   support\n\n           0       0.92      0.80      0.86     20463\n           1       0.50      0.76      0.60      5569\n\n    accuracy                           0.79     26032\n   macro avg       0.71      0.78      0.73     26032\nweighted avg       0.83      0.79      0.80     26032\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = df_test\ny_test = model.predict_proba(X_test)[:,1]\nprint(y_test)\nsubmission = pd.DataFrame({\n        \"encounter_id\": test_id,\n        \"diabetes_mellitus\": y_test\n        })\nsubmission = submission.sort_values(by=['encounter_id'])\nprint(submission)\nsubmission.to_csv('Submission.csv', index=False)","execution_count":160,"outputs":[{"output_type":"stream","text":"[0.15065022 0.37883891 0.47178786 ... 0.27819795 0.02921871 0.03736134]\n       encounter_id  diabetes_mellitus\n371          135000           0.312187\n6208         135001           0.031436\n3684         135002           0.144181\n3687         135003           0.421604\n10012        135004           0.018621\n...             ...                ...\n3724         145996           0.572121\n9947         145997           0.305848\n9751         145998           0.380083\n2118         145999           0.255119\n7894         146000           0.804198\n\n[10234 rows x 2 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfrom sklearn.model_selection import GridSearchCV\nparam_1 ={'n_estimators': [10,20,50,80,90,100,120,130], 'learning_rate': [0.08, 0.1,0.12]}\nparam_2 ={'num_leaves':[60,64,70,80,90,100],'max_depth':[8,9,10,11]}\ngbm = LGBMClassifier(random_state=999, tree_method = 'gpu_hist',boosting_type='gbdt', num_leaves=64)\ngrid_search = GridSearchCV(gbm, param_1, scoring='roc_auc',n_jobs=-1)\ngrid_search.fit(X_rdm,y_rdm)\ngrid_search.best_params_\n\"\"\"","execution_count":146,"outputs":[{"output_type":"execute_result","execution_count":146,"data":{"text/plain":"\"\\nfrom sklearn.model_selection import GridSearchCV\\nparam_1 ={'n_estimators': [10,20,50,80,90,100,120,130], 'learning_rate': [0.08, 0.1,0.12]}\\nparam_2 ={'num_leaves':[60,64,70,80,90,100],'max_depth':[8,9,10,11]}\\ngbm = LGBMClassifier(random_state=999, tree_method = 'gpu_hist',boosting_type='gbdt', num_leaves=64)\\ngrid_search = GridSearchCV(gbm, param_1, scoring='roc_auc',n_jobs=-1)\\ngrid_search.fit(X_rdm,y_rdm)\\ngrid_search.best_params_\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfeatures = X_train.columns\nprint(f\"AUC is {roc_auc_score(y_valid, grid_search.predict(X_valid))}\")\nprint(metrics.classification_report(y_valid, grid_search.predict(X_valid), labels=[0, 1]))\n\"\"\"","execution_count":147,"outputs":[{"output_type":"execute_result","execution_count":147,"data":{"text/plain":"'\\nfeatures = X_train.columns\\nprint(f\"AUC is {roc_auc_score(y_valid, grid_search.predict(X_valid))}\")\\nprint(metrics.classification_report(y_valid, grid_search.predict(X_valid), labels=[0, 1]))\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}